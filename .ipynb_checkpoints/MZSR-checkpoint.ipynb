{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afcee4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import *\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5225f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import functions, datasets, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30384e19-c3a4-43c3-a65e-4eea2ec6a826",
   "metadata": {},
   "source": [
    "### Sprawdzanie dostępności karty graficznej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151027dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f893b4-08b1-4569-b9c1-e5715b73ab24",
   "metadata": {},
   "source": [
    "Definowanie modelu składającego się z 8 warst kowolucyjnych o filtra wielkości 3x3. Warstwy ukryte posiadają funkcje aktywacji 'ReLU'. Wagi będą inicjalizowane przy użyciu funkcji Kaiming, natomiast obiążenie będzie równe 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e89f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 3, padding='same')\n",
    "        )\n",
    "        \n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                torch.nn.init.zeros_(m.bias)\n",
    "            \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pred = self.stack(x)\n",
    "        return x + pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f0b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911dbbaf-528f-4af4-81ed-deb8e0897669",
   "metadata": {},
   "source": [
    "## Wstępne uczenie sieci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e4f1a-c814-4223-a36a-dc322e6da882",
   "metadata": {},
   "source": [
    "Wszytywanie zbioru wykorzystywanego w procesie wstępnęgo uczenia\n",
    "\n",
    "Aby notebook działał powinieneś wcześniej wygenerować zbiór uczący z wykorzystaniem skryptu \"generate_dataset_MZSR.py\" w głównym katalogu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff6eb26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = datasets.MZSRPreTrain(\n",
    "    'datasets/train_SR_X2.dataset',\n",
    "    transform=ToTensor(),\n",
    "    target_transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f5470-88d8-4969-b6e6-eec04e794c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = training_data[1][0].cpu().detach().numpy()\n",
    "pred = np.moveaxis(pred, 0, -1)\n",
    "\n",
    "plt.imshow(pred)\n",
    "plt.show()\n",
    "\n",
    "pred = training_data[1][1].cpu().detach().numpy()\n",
    "pred = np.moveaxis(pred, 0, -1)\n",
    "\n",
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(scheduler.get_last_lr())\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f5a32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n",
    "decay_rate = 0.5\n",
    "decay_step = 1e5\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: max(0.25, decay_rate ** (32 * epoch // decay_step)))\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    pre_train(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "    torch.save(model.state_dict(), 'models/MZSR_pretrained.model')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9949db02-a3ae-46d9-bf96-7198519fdf3d",
   "metadata": {},
   "source": [
    "## Wszytywanie zbioru wykorzystywanego w procesie meta-uczenia\n",
    "Wczytywanie wag nauczonych na etapie wstępnego uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97966d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('models/MZSR_pretrained.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d336c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = datasets.MZSRMetaTrain(\n",
    "    'datasets/train_SR_MZSR.dataset',\n",
    "    transform=ToTensor(),\n",
    "    target_transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4b256-256d-436e-86c7-ad8cabb165d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = training_data[0][0].cpu().detach().numpy()\n",
    "pred = np.moveaxis(pred, 0, -1)\n",
    "\n",
    "plt.imshow(pred)\n",
    "plt.show()\n",
    "\n",
    "pred = training_data[0][1].cpu().detach().numpy()\n",
    "pred = np.moveaxis(pred, 0, -1)\n",
    "\n",
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2fa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import learn2learn as l2l\n",
    "import tqdm\n",
    "\n",
    "class MetaTrainer:\n",
    "    def __init__(self, dataset, model, alpha=1e-2, beta=1e-4, loss_fn=nn.L1Loss(), task_iter=5, batch_size=5, task_batch=8):\n",
    "        self.dataset = dataset\n",
    "        self.dataloader = DataLoader(dataset, batch_size=2*task_batch, shuffle=True, pin_memory=True)\n",
    "        \n",
    "        self.task_iter = task_iter\n",
    "        self.loss = loss_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.task_batch = task_batch\n",
    "        self.step = 0\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.maml_model = l2l.algorithms.MAML(model, lr=alpha, first_order=False)\n",
    "        self.optimizer = torch.optim.Adam(self.maml_model.parameters(), lr=self.beta)\n",
    "        \n",
    "\n",
    "    def adapt(self, batch, learner):\n",
    "        data, labels = batch\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        # Separate data into adaptation/evalutation sets\n",
    "        adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
    "        adaptation_indices[range(0, data.size(0), 2)] = True\n",
    "        evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
    "        adaptation_indices = torch.from_numpy(adaptation_indices)\n",
    "        adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
    "        evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
    "\n",
    "        pretrain_error = self.loss(learner(adaptation_data), adaptation_labels)\n",
    "        learner.adapt(pretrain_error)\n",
    "\n",
    "        predictions = learner(evaluation_data)\n",
    "        valid_error = self.loss(predictions, evaluation_labels)\n",
    "\n",
    "        meta_train_error = valid_error * self.loss_weight[0]\n",
    "        \n",
    "        # Adapt the model\n",
    "        for step in range(1, self.task_iter):\n",
    "            train_error = self.loss(learner(adaptation_data), adaptation_labels)\n",
    "            learner.adapt(train_error)\n",
    "            \n",
    "            predictions = learner(evaluation_data)\n",
    "            valid_error = self.loss(predictions, evaluation_labels)\n",
    "            \n",
    "            meta_train_error = meta_train_error + valid_error * self.loss_weight[step]\n",
    "                \n",
    "        return meta_train_error / self.batch_size, float(pretrain_error), float(meta_train_error)\n",
    "\n",
    "    def meta_train(self, epochs=5):\n",
    "        for t in range(epochs):\n",
    "            tqdm.tqdm.write(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            self.epoch()\n",
    "            torch.save(model.state_dict(), f'models/MZSR_meta-learned-{t+1}.model')\n",
    "        print(\"Done!\")\n",
    "        \n",
    "    def reduce_loss(self, loss):\n",
    "        error = loss[0]\n",
    "        \n",
    "        for i in loss[1:]:\n",
    "            error = error + i\n",
    "            \n",
    "        return i\n",
    "            \n",
    "    def epoch(self):\n",
    "        pbar = tqdm.tqdm(self.dataloader)\n",
    "        \n",
    "        for num, batch in enumerate(pbar):\n",
    "            if num % self.batch_size == 0:\n",
    "                self.optimizer.zero_grad()\n",
    "                self.loss_weight = self.get_loss_weights(self.step)\n",
    "            \n",
    "                pretrain_losses = 0\n",
    "                meta_train_losses = 0\n",
    "\n",
    "            # Compute meta-training loss\n",
    "            learner = self.maml_model.clone()\n",
    "            error, pretrain_error, meta_train_error = self.adapt(batch,\n",
    "                                                                 learner)\n",
    "            pretrain_losses += pretrain_error / 8\n",
    "            meta_train_error += meta_train_error / 8\n",
    "            error.backward()\n",
    "\n",
    "            self.dataloader.dataset.regenerate_kernel()\n",
    "            \n",
    "            # print(num)\n",
    "\n",
    "            if (num + 1) % self.batch_size == 0:\n",
    "                self.optimizer.step()\n",
    "                self.step += 1\n",
    "                pbar.set_postfix({'loss': f'[{float(pretrain_losses):>7f}, {float(meta_train_error):>7f}]'})\n",
    "    \n",
    "    def get_loss_weights(self, step):\n",
    "        loss_weights = np.ones(shape=(self.task_iter)) * (1.0 / self.task_iter)\n",
    "        decay_rate = 1.0 / self.task_iter / (10000 / 3)\n",
    "        min_value= 0.03 / self.task_iter\n",
    "        \n",
    "        loss_weights_pre = np.maximum(loss_weights[:-1] - step * decay_rate, np.ones(shape=(self.task_iter-1)) * min_value)\n",
    "        loss_weight_cur= np.minimum(loss_weights[-1] + step * decay_rate * (self.task_iter-1), 1.0 - ((self.task_iter - 1) * min_value))\n",
    "        \n",
    "        loss_weights = np.concatenate((loss_weights_pre, [loss_weight_cur]))\n",
    "        return loss_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eea8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = MetaTrainer(training_data, model, task_iter=5)\n",
    "\n",
    "trainer.meta_train(epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc1906-72ae-4c04-a9ad-545f5887e702",
   "metadata": {},
   "source": [
    "## Testowanie nauczonego modelu\n",
    "\n",
    "Funkcja zapisuje 4 zdjęcia w katalogu result: zdjęcie w niskiej rozdzielczości (low), wynik działania algorytmu 'bicubic' (bicubic), wynik działania sieci bez douczania (init) oraz wynik po wykonaniu douczenia z wykorzystaniem idealnego kernela zmniejszającego (trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283a77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gkernel\n",
    "import scipy.io as sio\n",
    "from image_resize import *\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "def meta_test(model, sample_number, dataset=None):\n",
    "    model.load_state_dict(torch.load('models/MZSR_meta-learned-3.model'))\n",
    "    # load()\n",
    "    kernel = gkernel.anisotropic_Gaussian(15, 0, 0.2, 0.2)\n",
    "    \n",
    "    path = 'datasets/'\n",
    "    results_path = 'results/'\n",
    "    if dataset == 'Urban':\n",
    "        path += 'Urban100/img_'\n",
    "        results_path += 'Urban100/'\n",
    "    else:\n",
    "        path += 'DIV2K/DIV2K/DIV2K_valid_HR/'\n",
    "        results_path += 'DIV2K/'\n",
    "        \n",
    "    hr_image = mpimg.imread(f'{path}{sample_number}.png') #Urban100/img_085.png\n",
    "        \n",
    "    train_lr_image = image_resize(hr_image, scale=1/2, kernel=kernel).astype(np.float32)\n",
    "    \n",
    "    image = Image.fromarray(np.uint8(train_lr_image*255), mode='RGB')\n",
    "    image.save(f'{results_path}{sample_number}-low.png')\n",
    "    \n",
    "    training_data = datasets.MZSRMetaTest(\n",
    "        train_lr_image,\n",
    "        kernel,\n",
    "        transform=ToTensor(),\n",
    "        target_transform=ToTensor()\n",
    "    )\n",
    "    dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "    \n",
    "    lr_image = image_resize(train_lr_image, scale=2, kernel='cubic').astype(np.float32)\n",
    "    image = Image.fromarray(np.uint8(np.clip(lr_image, 0, 1)*255), mode='RGB')\n",
    "    image.save(f'{results_path}{sample_number}-bicubic.png')\n",
    "    \n",
    "    print(metrics.PSNR(np.clip(lr_image, 0, 1), hr_image))\n",
    "    print(metrics.SSIM(np.clip(lr_image, 0, 1), hr_image))\n",
    "    \n",
    "    train_lr_image = ToTensor()(train_lr_image)\n",
    "    train_lr_image = train_lr_image[None]\n",
    "    \n",
    "    lr_image = ToTensor()(lr_image)\n",
    "    lr_image = lr_image[None]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = lr_image.to(device)\n",
    "        pred = model(X)\n",
    "        \n",
    "        pred = pred.cpu().detach().numpy()[0]\n",
    "        pred = np.moveaxis(pred, 0, -1)\n",
    "\n",
    "        pred = pred.clip(0, 1)\n",
    "        image = Image.fromarray(np.uint8(pred*255), mode='RGB')\n",
    "        image.save(f'{results_path}{sample_number}-init.png')\n",
    "        \n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for i in range(5):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = lr_image.to(device)\n",
    "        pred = model(X)\n",
    "        \n",
    "        pred = pred.cpu().detach().numpy()[0]\n",
    "        pred = np.moveaxis(pred, 0, -1)\n",
    "\n",
    "        pred = pred.clip(0, 1)\n",
    "        image = Image.fromarray(np.uint8(pred*255), mode='RGB')\n",
    "        image.save(f'{results_path}{sample_number}-trained.png')\n",
    "        \n",
    "#for i in range(801, 901):\n",
    "#    meta_test(model, '0' + str(i))\n",
    "    \n",
    "meta_test(model, '085', dataset='Urban')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
