{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r04vpbBbk5-Z"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import vgg16_bn\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from scipy import ndimage\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch.utils.data import Dataset\n",
    "from torch import is_tensor, FloatTensor,tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Mg5yQa0Y85S",
    "outputId": "6f5757b8-eb97-4a44-81fb-ded68d683602"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5FNYz-ylLIg"
   },
   "outputs": [],
   "source": [
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to4cjCrBsFcv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def measure(fun):\n",
    "    def wrapper(self):\n",
    "      start = time.time()\n",
    "      fun(self)\n",
    "      end = time.time()\n",
    "      self.time = end - start\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "class AbstractModel:\n",
    "    def __init__(self):\n",
    "        self.gt_image = None\n",
    "        self.lr_image = None\n",
    "        self.result = None\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_result(self) -> np.array:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return [PSNR(np.array(self.result), np.array(self.gt_image)), SSIM(np.array(self.result), np.array(self.gt_image)), self.time]\n",
    "\n",
    "    def set_input(self, lr_image: PIL.Image, gt_image: PIL.Image):\n",
    "        self.lr_image = np.array(lr_image)\n",
    "        self.gt_image = np.array(gt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1ZPs7v2wXsW"
   },
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss\n",
    "\n",
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)\n",
    "\n",
    "\n",
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "\n",
    "    def __del__(self): self.hooks.remove()\n",
    "\n",
    "\n",
    "class UNetModel(AbstractModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = load_learner('models')\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return 'UNet_Model_Nowszy'\n",
    "\n",
    "    @measure\n",
    "    def predict(self):\n",
    "        patch_size = 256\n",
    "        x = 8\n",
    "        image = self.lr_image\n",
    "        temp = np.zeros([int(np.ceil((image.shape[0])/(patch_size-2*x)))*patch_size, int(np.ceil(image.shape[1]/(patch_size-2*x)))*patch_size, 3])\n",
    "        result = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
    "        temp[x:image.shape[0]+x, x:image.shape[1]+x] = image\n",
    "        for i in range(0, temp.shape[0] - patch_size + x +1, patch_size - 2*x):\n",
    "          for j in range(0, temp.shape[1] - patch_size + x + 1 , patch_size - 2*x):\n",
    "\n",
    "            j_end = j + patch_size\n",
    "            im = temp[i:i+patch_size, j:j+patch_size]\n",
    "            imx = pil2tensor(im ,np.float32)\n",
    "            pred = self.model.predict(Image(imx))\n",
    "            pred = np.moveaxis(pred[2].numpy(),0,-1)/255\n",
    "            pred = np.clip(pred, 0, 1)\n",
    "            result[i:(i+patch_size-2*x), j:(j+patch_size-2*x)] = pred[x:-x, x:-x]\n",
    "\n",
    "        self.result =  result[:image.shape[0], :image.shape[1]]\n",
    "\n",
    "    def get_result(self) -> np.array:\n",
    "        return self.result\n",
    "\n",
    "    def set_input(self, lr_image: PIL.Image, gt_image: PIL.Image):\n",
    "        super().set_input(lr_image.resize((lr_image.size[0]*2, lr_image.size[1]*2), resample=PIL.Image.BILINEAR).convert('RGB'), gt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17TZP6gf7pNO"
   },
   "outputs": [],
   "source": [
    "\n",
    "class KPNLPModel(AbstractModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = KPNLPnetwork().to(device)\n",
    "        self.model.load_state_dict(torch.load('models/KPNLPresidual.model' , map_location=torch.device(device)))\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return 'KPNLP_Model'\n",
    "\n",
    "    @measure\n",
    "    def predict(self):\n",
    "        img = np.moveaxis(self.lr_image, -1, 0)\n",
    "        #print(img.shape)\n",
    "        lr_image = FloatTensor(img)[None,:]\n",
    "        lr_image_y = (16+ lr_image[..., 0, :, :]*0.25679 + lr_image[..., 1, :, :]*0.504 + lr_image[..., 2, :, :]*0.09791)/255\n",
    "        lr_image_y = lr_image_y[None , :, :].to(device)\n",
    "        lr_image_cb = (128 - 37.945*lr_image[..., 0, :, :]/256 - 74.494*lr_image[..., 1, :, :]/256 + 112.439*lr_image[..., 2, :, :]/256)\n",
    "        lr_image_cr = (128 + 112.439*lr_image[..., 0, :, :]/256 - 94.154*lr_image[..., 1, :, :]/256 - 18.285*lr_image[..., 2, :, :]/256)\n",
    "        hr_cb = nn.functional.interpolate(lr_image_cb[None , :,:],scale_factor = 2 , mode='bicubic').detach().numpy()[0,0]\n",
    "        hr_cr = nn.functional.interpolate(lr_image_cr[None , :,:],scale_factor = 2 , mode='bicubic').detach().numpy()[0,0]\n",
    "        pom = self.model(lr_image_y)\n",
    "        pom2 = pom.to('cpu').detach().numpy()[0,0]\n",
    "        pom2 *= 255\n",
    "        pom2 = np.clip(pom2 , 0, 255)\n",
    "        hr_cr = np.clip(hr_cr, 0, 255)\n",
    "        hr_cb = np.clip(hr_cb , 0, 255)\n",
    "        r = pom2 + 1.402 *(hr_cr - 128)\n",
    "        g = pom2 - 0.344136*(hr_cb - 128) - 0.714136 *(hr_cr-128)\n",
    "        b = pom2 + 1.772* (hr_cb - 128)\n",
    "        self.result = np.dstack((r,g,b)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    def get_result(self) -> np.array:\n",
    "        return self.result\n",
    "\n",
    "    def set_input(self, lr_image: PIL.Image, gt_image: PIL.Image):\n",
    "        super().set_input(lr_image, gt_image)\n",
    "\n",
    "        #print(self.lr_image.shape)\n",
    "        h_pad = (4 - self.lr_image.shape[0] % 4)%4\n",
    "        w_pad = (4- self.lr_image.shape[1] % 4)%4\n",
    "        self.lr_image = np.pad(self.lr_image , ((0, h_pad), (0, w_pad) , (0 ,0)) )\n",
    "        self.gt_image = np.pad(self.gt_image , ((0, 2*h_pad), (0, 2*w_pad), (0 ,0)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgVhRvep8eAO"
   },
   "outputs": [],
   "source": [
    "class KPNLPnetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KPNLPnetwork, self).__init__()\n",
    "        self.kernel = (1.0/100)*torch.tensor([[[[1, 4, 6, 4, 1],[4, 16, 24, 16, 4],[6, 24, 36, 24, 6], [4, 16, 24, 16, 4],[1, 4, 6, 4, 1]]]])\n",
    "        self.downsample = nn.PixelUnshuffle(4)\n",
    "        self.conv1a = nn.Conv2d(16 , 64 , 3 , padding=1)\n",
    "        self.conv1b = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1qa = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1qb = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1ha = nn.Conv2d(16, 64, 3, padding=1)\n",
    "        self.conv1hb = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1fa = nn.Conv2d(4, 64, 3, padding=1)\n",
    "        self.conv1fb = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.stack1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack6 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack8 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack9 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack10 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack11 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack12 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack13 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack14 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack15 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.stack16 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1))\n",
    "        self.upsample2 = nn.PixelShuffle(2)\n",
    "        self.upsample4 = nn.PixelShuffle(4)\n",
    "        self.conv2q = nn.Conv2d(64, 25 , 3 , padding=1)\n",
    "        self.conv2h = nn.Conv2d(64, 25, 3, padding=1)\n",
    "        self.conv2f = nn.Conv2d(64, 25, 3, padding=1)\n",
    "        self.conv3q = nn.Conv2d(25 , 1 , 5, padding='same')\n",
    "        self.conv3h = nn.Conv2d(25, 1, 5, padding='same')\n",
    "        self.conv3f = nn.Conv2d(25, 1, 5, padding='same')\n",
    "        \n",
    "        self.pyrConv = nn.Conv2d(1 ,1 ,5 , padding=\"same\" , bias=False)\n",
    "        \n",
    "        self.pyrConv.weight = nn.Parameter(self.kernel)\n",
    "        \n",
    "        self.normalUp = nn.Upsample(scale_factor  = 2 , mode='bicubic')\n",
    "        self.padLayer = nn.ZeroPad2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.normalUp(x) \n",
    "        #print(x.shape , x.dtype)\n",
    "        common = self.downsample(x)\n",
    "        #print(common.shape , common.dtype)\n",
    "        common = self.conv1a(common)\n",
    "        common = self.relu(common)\n",
    "        #print(common.shape , common.dtype)\n",
    "        pom = self.stack1(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack2(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack3(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack4(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack5(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack6(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack7(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack8(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack9(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack10(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack11(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack12(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack13(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack14(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack15(common)\n",
    "        common = common + pom\n",
    "        pom = self.stack16(common)\n",
    "        common = common + pom\n",
    "        common = self.conv1b(common)\n",
    "        common = self.relu(common)\n",
    "        quarter = common\n",
    "        quarter = self.conv1qa(quarter)\n",
    "        quarter = self.relu(quarter)\n",
    "        quarter = self.conv1qb(quarter)\n",
    "        quarter = self.relu(quarter)\n",
    "        quarter = self.conv2q(quarter)\n",
    "        quarter = self.relu(quarter)\n",
    "        \n",
    "        half = self.upsample2(common)\n",
    "        full = self.upsample4(common)\n",
    "        \n",
    "        half = self.conv1ha(half)\n",
    "        half = self.relu(half)\n",
    "        half = self.conv1hb(half)\n",
    "        half = self.relu(half)\n",
    "        half = self.conv2h(half)\n",
    "        half = self.relu(half)\n",
    "        \n",
    "\n",
    "        full = self.conv1fa(full)\n",
    "        full = self.relu(full)\n",
    "        full = self.conv1fb(full)\n",
    "        full = self.relu(full)\n",
    "        full = self.conv2f(full)\n",
    "        full = self.relu(full)\n",
    "        h = x.shape[2]\n",
    "        w = x.shape[3]\n",
    "        padded = self.padLayer(x).to(device)\n",
    "        #padded = nn.functional.pad(x , (2,2,2,2) )\n",
    "        nq = torch.empty(x.shape[0] , 25, h//4, w//4).to(device)\n",
    "        nh = torch.empty(x.shape[0] , 25, h//2, w//2).to(device)\n",
    "        c = torch.empty(x.shape[0] , 25, h, w ).to(device)\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                #temp = padded[... , 0, i:i+5 , j:j+5]\n",
    "                c[...,:,i,j] = torch.flatten(padded[... , 0, i:i+5 , j:j+5] , start_dim=1)\n",
    "        d = full*c\n",
    "        e = torch.sum(d , 1, keepdim  = True)\n",
    "\n",
    "        for i in range(h//2):\n",
    "            pom_i = i*2\n",
    "            for j in range(w//2):\n",
    "                pom_j = j*2\n",
    "                nh[...,:,i,j] = torch.flatten(padded[... , 0, pom_i:pom_i+5 , pom_j:pom_j+5] , start_dim=1)\n",
    "        dh = half*nh\n",
    "        eh = torch.sum(dh , 1, keepdim  = True)\n",
    "\n",
    "        \n",
    "        for i in range(h//4):\n",
    "            pom_i = i*4\n",
    "            for j in range(w//4):\n",
    "                pom_j = j*4\n",
    "                nq[...,:,i,j] = torch.flatten(padded[... , 0, pom_i:pom_i+5 , pom_j:pom_j+5] , start_dim=1)\n",
    "        dq = quarter*nq\n",
    "        eq = torch.sum(dq , 1, keepdim  = True)\n",
    "\n",
    "        eq = self.normalUp(eq)\n",
    "        eq = self.pyrConv(eq)  #zakomentowane od (2) \n",
    "        eh = eh+ eq\n",
    "        eh = self.normalUp(eh)\n",
    "        eh = self.pyrConv(eh)  #zakomentowane od (2) \n",
    "        e = eh+ e\n",
    "\n",
    "        \n",
    "        #e = self.pyrConv(e)       #zakomentowane od (2)\n",
    "        c.detach()\n",
    "        eh.detach()\n",
    "        eq.detach()\n",
    "        padded.detach()                 \n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    image = np.array(image)\n",
    "    image = np.moveaxis(image, 0, -1)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_projection(y_sr, y_lr, down_kernel='cubic', up_kernel='cubic', sf=None, ds_method='direct'):\n",
    "    y_sr += image_resize(y_lr - image_resize(y_sr, scale=1.0/sf, output_shape=y_lr.shape, kernel=down_kernel, ds_method=ds_method),\n",
    "                     scale=sf,\n",
    "                     output_shape=y_sr.shape,\n",
    "                     kernel=up_kernel)\n",
    "    return np.clip(y_sr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIccJDumSZ0C"
   },
   "outputs": [],
   "source": [
    "sys.path.append('MZSR')\n",
    "sys.path.append('KernelGAN')\n",
    "\n",
    "from utils import datasets\n",
    "from image_resize import image_resize\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from configs import Config\n",
    "from data import DataGenerator\n",
    "from kernelGAN import KernelGAN\n",
    "from learner import Learner\n",
    "import torch\n",
    "\n",
    "class MZSRNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MZSRNetwork, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 3, padding='same')\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pred = self.stack(x)\n",
    "        return x + pred\n",
    "\n",
    "class MZSRModel(AbstractModel):\n",
    "    def __init__(self, bicubic=False):\n",
    "        self.gt_image = None\n",
    "        self.lr_image = None\n",
    "        self.result = None\n",
    "        self.bicubic = bicubic\n",
    "        self.model = MZSRNetwork().to(device)\n",
    "        self.conf = Config(device).parse()\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        name = 'MZSR_'\n",
    "        name += 'bicubic' if self.bicubic else 'kernelGan'\n",
    "        return name\n",
    "\n",
    "    @measure\n",
    "    def predict(self):\n",
    "        loss_fn = nn.L1Loss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=2.5e-4)\n",
    "        self.model.load_state_dict(torch.load('models/MZSR.model', map_location=torch.device(device)))\n",
    "\n",
    "        if self.bicubic:\n",
    "            kernel = 'cubic'\n",
    "        else:\n",
    "            gan = KernelGAN(self.conf)\n",
    "            learner = Learner()\n",
    "            data = DataGenerator(self.conf, gan, self.lr_image, device)\n",
    "\n",
    "            for iteration in range(3000):\n",
    "                [g_in, d_in] = data.__getitem__(iteration)\n",
    "                gan.train(g_in, d_in)\n",
    "                learner.update(iteration, gan)\n",
    "\n",
    "            kernel = gan.finish()\n",
    "            print(np.sum(kernel))\n",
    "            plt.imshow(kernel, cmap='gray')\n",
    "            plt.show()\n",
    "        \n",
    "        training_data = datasets.MZSRMetaTest(\n",
    "            self.lr_image,\n",
    "            kernel,\n",
    "            transform=ToTensor(),\n",
    "            target_transform=ToTensor()\n",
    "        )\n",
    "        \n",
    "        # show_image(training_data[10][0])\n",
    "        # show_image(training_data[10][1])\n",
    "        \n",
    "        lr_son = image_resize(self.lr_image, scale=1/2, kernel=kernel).astype(np.float32)\n",
    "        lr_son = image_resize(lr_son, scale=2, kernel='cubic').astype(np.float32)\n",
    "        lr_son = ToTensor()(lr_son)\n",
    "        lr_son = lr_son[None]\n",
    "        # plt.imshow(lr_image)\n",
    "        # plt.show()\n",
    "        \n",
    "        dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "        \n",
    "        lr_image = ToTensor()(self.lr_image)\n",
    "        lr_image = lr_image[None]\n",
    "\n",
    "        self.model.train()\n",
    "        size = len(dataloader.dataset)\n",
    "        for i in range(10):\n",
    "            # for batch, (X, y) in enumerate(dataloader):\n",
    "                X, y = lr_son.to(device), lr_image.to(device)\n",
    "\n",
    "                pred = self.model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        lr_image = image_resize(self.lr_image, scale=2, kernel='cubic').astype(np.float32)\n",
    "        lr_image = ToTensor()(lr_image)\n",
    "        lr_image = lr_image[None]\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X = lr_image.to(device)\n",
    "            \n",
    "            if not self.bicubic:\n",
    "                outputs = []\n",
    "                \n",
    "                X = torch.moveaxis(lr_image[0], 0, -1)\n",
    "                for k in range(8):\n",
    "                    # Rotate 90*k degrees and mirror flip when k>=4\n",
    "                    test_input = torch.rot90(X, k, (0, 1)) if k < 4 else torch.fliplr(torch.rot90(X, k, (0, 1)))\n",
    "                    \n",
    "                    tmp_output = test_input.cpu().detach().numpy()\n",
    "\n",
    "                    test_input = torch.moveaxis(test_input, -1, 0)[None]\n",
    "                    # Apply network on the rotated input\n",
    "                    tmp_output = self.model(test_input.cuda())\n",
    "\n",
    "                    tmp_output = torch.moveaxis(tmp_output[0], 0, -1)\n",
    "                    # Undo the rotation for the processed output (mind the opposite order of the flip and the rotation)\n",
    "                    tmp_output = torch.rot90(tmp_output, -k, (0, 1)) if k < 4 else torch.rot90(torch.fliplr(tmp_output), -k, (0, 1))\n",
    "                    tmp_output = tmp_output.cpu().detach().numpy()\n",
    "                    \n",
    "                    for _ in range(2):\n",
    "                        tmp_output = back_projection(tmp_output, self.lr_image, sf=2)\n",
    "                    \n",
    "                    # save outputs from all augmentations\n",
    "                    outputs.append(tmp_output)\n",
    "                \n",
    "                self.result = np.median(outputs, 0)\n",
    "                \n",
    "                for _ in range(2):\n",
    "                    self.result = back_projection(self.result, self.lr_image, sf=2)\n",
    "                \n",
    "                #for _ in range(2):\n",
    "                #    self.result = back_projection(self.result, self.lr_image, sf=2)\n",
    "            else:\n",
    "                pred = self.model(X)\n",
    "                pred = pred.cpu().detach().numpy()[0]\n",
    "                self.result = np.moveaxis(pred, 0, -1)     \n",
    "            \n",
    "            \"\"\"if not self.bicubic:\n",
    "                for _ in range(5):\n",
    "                    self.result = back_projection(self.result, self.lr_image, sf=2)\"\"\"\n",
    "                    \n",
    "            self.result = self.result.clip(0, 1)\n",
    "\n",
    "    def get_result(self) -> np.array:\n",
    "        return self.result\n",
    "\n",
    "    def set_input(self, lr_image: np.array, gt_image: np.array):\n",
    "        super().set_input(lr_image, gt_image)\n",
    "        self.lr_image = self.lr_image.astype(np.float32) / 255\n",
    "        self.gt_image = self.gt_image.astype(np.float32) /  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExlXTsdb50Rq"
   },
   "outputs": [],
   "source": [
    "class BicubicModel(AbstractModel):\n",
    "    def __init__(self, bicubic=False):\n",
    "        self.gt_image = None\n",
    "        self.lr_image = None\n",
    "        self.result = None\n",
    "\n",
    "    def get_name(self) -> str:\n",
    "        return 'bicubic'\n",
    "\n",
    "    @measure\n",
    "    def predict(self):\n",
    "        self.result = image_resize(self.lr_image, scale=2, kernel='cubic').astype(np.float32).clip(0, 1)\n",
    "    \n",
    "    def get_result(self) -> np.array:\n",
    "        return self.result\n",
    "\n",
    "    def set_input(self, lr_image: np.array, gt_image: np.array):\n",
    "        super().set_input(lr_image, gt_image)\n",
    "        self.lr_image = self.lr_image.astype(np.float32) / 255\n",
    "        self.gt_image = self.gt_image.astype(np.float32) /  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jhpj_h6RPiX6"
   },
   "outputs": [],
   "source": [
    "def get_tests(path):\n",
    "  result = []\n",
    "  \n",
    "  with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "      while line[-1] == '\\n':\n",
    "        line = line[:-1]\n",
    "\n",
    "      result.append(line.split(';'))\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J98BNTfDmtxD"
   },
   "outputs": [],
   "source": [
    "def test_on_dataset(path, dataset_lr, dataset_gt, models):\n",
    "  lista=os.listdir(path/'datasets'/dataset_lr)\n",
    "  metrics = [open(path/f'results/{dataset_lr}_{i.get_name()}.csv', 'w') for i in models]\n",
    "\n",
    "  for i in metrics:\n",
    "      i.write('Name;PSNR;SSIM;time\\n')\n",
    "  \n",
    "  p_result = path/'results'/dataset_lr\n",
    "\n",
    "  print(p_result)\n",
    "\n",
    "  for i in models:\n",
    "      os.makedirs(p_result/i.get_name(), exist_ok=True)\n",
    "\n",
    "    \n",
    "  pbar = tqdm(lista)\n",
    "  for i in pbar:\n",
    "      p_lr = f'datasets/{dataset_lr}/{i}'\n",
    "      p_gt = f'datasets/{dataset_gt}/{i}'\n",
    "\n",
    "      lr = PIL.Image.open(path/p_lr)\n",
    "      gt = PIL.Image.open(path/p_gt)\n",
    "\n",
    "      for j in range(len(models)):\n",
    "        pbar.set_postfix({'Model': models[j].get_name()})\n",
    "        \n",
    "        models[j].set_input(lr, gt)\n",
    "        models[j].predict()\n",
    "        result= models[j].get_result()\n",
    "        temp = p_result/models[j].get_name()/i\n",
    "        plt.imsave(temp, result)\n",
    "        img_metrics = models[j].get_metrics()\n",
    "\n",
    "        temp = str(i)\n",
    "\n",
    "        for metric in img_metrics:\n",
    "            temp += f';{metric}'\n",
    "\n",
    "        metrics[j].write(f'{temp}\\n')\n",
    "        metrics[j].flush()\n",
    "        os.fsync(metrics[j].fileno())\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "  for i in metrics:    \n",
    "      i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0YgGbmYoN0H",
    "outputId": "11c4c0bf-c54f-46f0-f0bf-1b772159dee1"
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (30, 30)\n",
    "\n",
    "models = [KPNLPModel()]\n",
    "# models = [UNetModel()]\n",
    "test_path = Path('test')\n",
    "\n",
    "tests = get_tests(test_path/'config.csv')\n",
    "\n",
    "for index, (hr, lr) in enumerate(tests):\n",
    "  print(f'{index+1}/{len(tests)}: {lr} -> {hr}')\n",
    "\n",
    "  test_on_dataset(test_path, lr, hr, models)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Testy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
